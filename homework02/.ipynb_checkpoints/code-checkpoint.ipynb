{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二题 实现3层的卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载\n",
    "通过pickle对原始的数据进行加载，并处理为一维的向量，可视化数据集中的图像，效果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 数据解压，类似与字典一样的数据，通过pickle来进行解压\n",
    "def load_data():\n",
    "    f = gzip.open('data/mnist.pkl.gz', 'rb')\n",
    "    train_data, val_data, test_data = pickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "# 数据处理，将二维的图像数据处理成实际上我们使用的数据\n",
    "def raw_data_preprocess():\n",
    "    raw_train_data, raw_val_data, raw_test_data = load_data()\n",
    "    # 处理训练数据\n",
    "    train_inputs = [np.reshape(x, (784, 1)) for x in raw_train_data[0]]\n",
    "    train_labels = [one_hot(y) for y in raw_train_data[1]]\n",
    "    train_data = zip(train_inputs, train_labels)\n",
    "    print(\"训练数据大小：{}\".format(len(train_labels)))\n",
    "    # 处理验证数据\n",
    "    val_inputs = [np.reshape(x, (784, 1)) for x in raw_val_data[0]]\n",
    "    val_labels = [one_hot(y) for y in raw_val_data[1]]\n",
    "    val_data = zip(val_inputs, val_labels)\n",
    "    print(\"验证数据大小：{}\".format(len(val_labels)))\n",
    "    # 处理测试数据\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in raw_test_data[0]]\n",
    "    test_labels = [one_hot(y) for y in raw_test_data[1]]\n",
    "    test_data = zip(test_inputs, test_labels)\n",
    "    print(\"测试数据大小：{}\".format(len(test_labels)))\n",
    "    print(\"mnist数据加载完毕\")\n",
    "    return list(train_data), list(val_data), list(test_data)\n",
    "\n",
    "\n",
    "# 将图片转化为onehot向量的形势\n",
    "def one_hot(j):\n",
    "    one_hot_j = np.zeros((10, 1))\n",
    "    one_hot_j[j] = 1.0\n",
    "    return one_hot_j\n",
    "\n",
    "\n",
    "def show_img(img_array):\n",
    "    img = Image.fromarray(img_array)\n",
    "    img_gray = img.convert(\"L\")\n",
    "    # pillow 读取完的图片还是具体的整数，没有做归一化的处理\n",
    "    # matplotlib做显示的时候显示的不是灰度图，是因为颜色通道的缘故\n",
    "    # print(img)\n",
    "    # print(np.array(img).shape)\n",
    "    plt.figure(\"Image\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"on\")\n",
    "    plt.title(\"mnist image\")\n",
    "    img_gray.save(\"test.jpg\", quality=95, subsampling=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据大小：50000\n",
      "验证数据大小：10000\n",
      "测试数据大小：10000\n",
      "mnist数据加载完毕\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = load_data()\n",
    "img_array = test_data[0][0]\n",
    "img_28_28 = img_array.reshape(28, 28) * 255\n",
    "img_28_28_int = img_28_28.astype(\"int\")\n",
    "show_img(img_28_28_int)\n",
    "t,v,test = raw_data_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完成mlp的搭建\n",
    "按照题目要求，中间隐藏层的激活函数选择relu，输出层的激活函数为softmax，一定要注意，使用了relu作为激活函数，最后一层是不使用relu的，直接对z进行softmax即可，代码和效果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def activate_function(z, name='relu'):\n",
    "    if name == 'relu':\n",
    "        z[z < 0] = 0\n",
    "        return z\n",
    "    # elif name == 'sigmoid':\n",
    "    #     return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def activate_function_prime(z, name='relu'):\n",
    "    if name == 'relu':\n",
    "        z[z > 0] = 1\n",
    "        z[z <= 0] = 0\n",
    "        return z\n",
    "    # elif name == 'sigmoid':\n",
    "    #     return activate_function(z, \"sigmoid\") * (1 - activate_function(z, \"sigmoid\"))\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    t = np.exp(z)\n",
    "    a = np.nan_to_num(np.exp(z) / np.sum(t))\n",
    "    return a\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "    # sizes 用来描述网络的结构，包括输入层、隐藏层和输出层\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        # randn 用来生成标准正态分布，生成的是列向量\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        # 生成正态分布的权重矩阵，其中后面一层的结点数目为网路的左下标，前面一层的结点数目为网络的右下表，方便进行矩阵运算\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    # 执行一次前向传播, 输出的是a，根据不同的损失函数去计算损失\n",
    "    def feedforward(self, a):\n",
    "        # 按照课上的ppt指出，如果是最后一层，只留下z即可, 不再进行进一步的激活\n",
    "        num_forward = 0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, a) + b\n",
    "            if num_forward < (self.num_layers - 2):\n",
    "                # print(\"relu\")\n",
    "                a = activate_function(z)\n",
    "            else:\n",
    "                # print(\"softmax\")\n",
    "                a = softmax(z)\n",
    "            num_forward = num_forward + 1\n",
    "        # todo 实际上这个位置返回的应该是z，而不是a\n",
    "        # y_hat = softmax(z)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, train_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        n = len(train_data)\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(train_data)\n",
    "            # 数据划分\n",
    "            mini_batches = [train_data[k: k + mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            # 小批量数据梯度更新\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                n_test = len(test_data)\n",
    "                correct_num = self.evaluate(test_data)\n",
    "                print(\"Epoch {} : {} / {}\".format(j, correct_num, n_test))\n",
    "            else:\n",
    "                print(\"Epoch {} complete\".format(j))\n",
    "        # 把一个合适的权重保存下来\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        # nabla用来表示微分，就是每一层求偏导之后的结果\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "\n",
    "        for x, y in mini_batch:\n",
    "            # 把这个小批量的梯度回\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "\n",
    "        # 终于开始梯度更新\n",
    "        self.weights = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        # 初始化w和b的微分\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # 前向传播\n",
    "        activation = x  # 一开始的那个a就是输入的x\n",
    "        activations = [x]  # 保存前向传播的a，也就是激活之后的值\n",
    "        zs = []  # 用来保存前向传播过程中的z，也就是累加之后的值\n",
    "        current_layer = 0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            # todo 如果是最后一层，请使用sigmoid激活函数，或者直接不整\n",
    "            if current_layer < (self.num_layers - 2):\n",
    "                # print(\"执行relu\")\n",
    "                activation = activate_function(z)\n",
    "            else:\n",
    "                # 最后一层不执行relu，仅执行sigmoid\n",
    "                # print(\"执行softmax\")\n",
    "                # activation = activate_function(z, name='sigmoid')\n",
    "                activation = softmax(z)\n",
    "            activations.append(activation)\n",
    "            current_layer = current_layer + 1\n",
    "\n",
    "        # 开始去计算误差并进行反向传播\n",
    "        # todo 反向传播的过程中，最后一层的误差其实也不去做偏导，从倒数第二层开始进行偏导\n",
    "        delta = self.cost_derivative(activations[-1], y)\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "\n",
    "        # 前面的层的误差通过后面层的误差去计算即可\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            afp = activate_function_prime(z)\n",
    "            delta = np.dot(self.weights[-l + 1].transpose(), delta) * afp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l - 1].transpose())\n",
    "        return nabla_b, nabla_w\n",
    "\n",
    "    def cost_derivative(self, out_put_activations, y, name='relu'):\n",
    "        if name == \"relu\":\n",
    "            return out_put_activations - y\n",
    "\n",
    "    # 验证准确率\n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), np.argmax(y)) for x, y in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def test_img(self, img_name):\n",
    "        img = Image.open(img_name)\n",
    "        img_array = np.array(img) / 255.0\n",
    "        img_array = img_array.reshape(784, 1)\n",
    "        label_one_hot = self.feedforward(img_array)\n",
    "        label = np.argmax(label_one_hot)\n",
    "        print(\"predict: {}\".format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据大小：50000\n",
      "验证数据大小：10000\n",
      "测试数据大小：10000\n",
      "mnist数据加载完毕\n",
      "Epoch 0 : 8462 / 10000\n",
      "Epoch 1 : 8831 / 10000\n",
      "Epoch 2 : 8947 / 10000\n",
      "Epoch 3 : 9012 / 10000\n",
      "Epoch 4 : 9076 / 10000\n",
      "Epoch 5 : 9121 / 10000\n",
      "Epoch 6 : 9122 / 10000\n",
      "Epoch 7 : 9158 / 10000\n",
      "Epoch 8 : 9194 / 10000\n",
      "Epoch 9 : 9170 / 10000\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = raw_data_preprocess()\n",
    "net = Network([784, 15, 10])\n",
    "net.SGD(train_data, 10, 10, 0.1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(imgname):\n",
    "#     img = Image.open(img).convert(\"L\")\n",
    "    img = plt.imread(imgname)\n",
    "    plt.figure(\"Image\")\n",
    "    plt.imshow(img,cmap ='gray')\n",
    "    plt.axis(\"on\")\n",
    "    plt.title(\"mnist image\")\n",
    "    plt.show()\n",
    "\n",
    "show_img(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 7\n"
     ]
    }
   ],
   "source": [
    "net.test_img(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "整个过程比较耗时，主要还是数学基础薄弱和编程逻辑不清晰，比如最后具体的激活过程整了好久才明白，望继续加强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
